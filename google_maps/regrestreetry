import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.tree import DecisionTreeRegressor, plot_tree
import numpy as np
import seaborn as sns

# Load the data
file_path = ("C:/Users/J. Teunisse/jupyter/rating_and_count.csv")
rating_and_count_df = pd.read_csv(file_path)

# Preparing the data
numeric_columns = rating_and_count_df.select_dtypes(include=['number']).columns
data = rating_and_count_df[numeric_columns]

# Remove 'index' column if it exists
if 'index' in data.columns:
    data = data.drop('index', axis=1)

X = data.drop('rating', axis=1).fillna(data.mean())  # Features, handling NaNs
y = data['rating']  # Target

# Splitting the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Hyperparameter tuning using grid search
param_grid = {
    'max_depth': [3, 5, 10, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
grid_search = GridSearchCV(DecisionTreeRegressor(random_state=42), param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_

# Creating and training the regression tree model with best parameters
reg_tree = DecisionTreeRegressor(random_state=42, **best_params)
reg_tree.fit(X_train, y_train)

# Pruning the tree
path = reg_tree.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas, impurities = path.ccp_alphas, path.impurities

# Exclude any ccp_alpha values that are not positive due to floating-point precision errors
ccp_alphas = ccp_alphas[ccp_alphas >= 0]

# Find the optimal ccp_alpha that maximizes cross-validation score
cv_scores = [np.mean(cross_val_score(DecisionTreeRegressor(random_state=42, ccp_alpha=alpha, **best_params),
                                      X_train, y_train, cv=5, scoring='neg_mean_squared_error'))
             for alpha in ccp_alphas]
optimal_ccp_alpha = ccp_alphas[np.argmax(cv_scores)]

# Retrain with the optimal ccp_alpha
reg_tree_pruned = DecisionTreeRegressor(random_state=42, ccp_alpha=optimal_ccp_alpha, **best_params)
reg_tree_pruned.fit(X_train, y_train)

# Visualizing the pruned tree with a larger figure size
plt.figure(figsize=(30, 20))
plot_tree(reg_tree_pruned, feature_names=X.columns, filled=True, proportion=False, rounded=True)
plt.savefig('tree_pruned.png', dpi=300)  # Saving the tree as a larger PNG
plt.close()  # Close the plot

# Extracting feature importances
feature_importances = reg_tree.feature_importances_
importance_df = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': feature_importances
}).sort_values(by='Importance', ascending=False)

# Plotting the feature importances
plt.figure(figsize=(10, 8))
sns.barplot(x='Importance', y='Feature', data=importance_df.head(10))
plt.title('Top 10 Feature Importances in the Regression Tree')
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.show()

# Initialize an empty list to store the impacts
impact_list = []

# Analyzing the impact of each variable on ratings
baseline_predictions = reg_tree.predict(X_test)
for feature in X_train.columns:
    modified_test_set = X_test.copy()
    modified_test_set[feature] = X_train[feature].mean()
    modified_predictions = reg_tree.predict(modified_test_set)
    impact_on_rating = (baseline_predictions - modified_predictions).mean()
    impact_list.append({'Feature': feature, 'Average Impact on Rating': impact_on_rating})

# Convert the list of impacts to a DataFrame and sort it by the absolute values
impact_df = pd.DataFrame(impact_list)
impact_df['Absolute Impact on Rating'] = impact_df['Average Impact on Rating'].abs()
impact_df = impact_df.sort_values(by='Absolute Impact on Rating', ascending=False)

# Displaying top 10 impacts for clarity with explanation
print("Top 10 features by average impact on rating (positive values indicate higher feature values correspond to higher ratings, while negative values indicate higher feature values correspond to lower ratings):\n")
print(impact_df.head(10).to_string(index=False))

# Performing k-fold cross-validation
cv_scores = cross_val_score(DecisionTreeRegressor(random_state=42, **best_params), 
                            X_train, y_train, 
                            cv=5, 
                            scoring='neg_mean_squared_error')

# Calculating the average and standard deviation of the cross-validation scores
cv_scores_mean = np.mean(cv_scores)
cv_scores_std = np.std(cv_scores)

# Displaying cross-validation results for clarity
print("Average Cross-Validation Score (Mean Squared Error):", cv_scores_mean)
print("Standard Deviation of Cross-Validation Score:", cv_scores_std)
